# -*- coding: utf-8 -*-
"""Linear Regression ML.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UoNW60KrwkvOCJm-nn5j4SleQtZSr9xY
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
# %matplotlib inline

# Load Boston House Pricing

from sklearn.datasets import load_boston

boston = load_boston()

boston.keys()

print(boston.DESCR)

print(boston.data)

print(boston.feature_names)

# Preparing the Dataset

dataset = pd.DataFrame(boston.data,columns=boston.feature_names)

dataset.head()

dataset["price"] = boston.target

dataset.head()

dataset.info()

## Summarizing the stats

dataset.describe()

# checking the missing values
dataset.isna().sum()

## Exploratory data analysis
# Correlation
dataset.corr()

import seaborn as sns
sns.pairplot(dataset)

plt.scatter(dataset["CRIM"],dataset["price"])
plt.xlabel("Crime rate")
plt.ylabel("Price")

plt.scatter(dataset["RM"],dataset["price"])
plt.xlabel("RM")
plt.ylabel("Price")

import seaborn as sns
sns.regplot(x="RM",y="price",data=dataset)

import seaborn as sns
sns.regplot(x="LSTAT",y="price",data=dataset)

import seaborn as sns
sns.regplot(x="CHAS",y="price",data=dataset)

import seaborn as sns
sns.regplot(x="PTRATIO",y="price",data=dataset)

## Independent and Dependent Features

x = dataset.iloc[:,:-1]
y = dataset.iloc[:,-1]

# Train Test split

from sklearn.model_selection import train_test_split

x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3,random_state=42)

x_train

y_train

from pandas.core.array_algos.replace import Scalar
# Standardize the dataset
from sklearn.preprocessing import StandardScaler
scalar = StandardScaler()

x_train = scalar.fit_transform(x_train)

x_test = scalar.fit_transform(x_test)

"""**Model** **Trainingg**"""

from sklearn.linear_model import LinearRegression
rg = LinearRegression()

model = rg.fit(x_train,y_train)

print(rg.coef_)

print(rg.intercept_)

rg.get_params()

rg_pred = model.predict(x_test)

plt.scatter(y_test,rg_pred)

# Errors
residuals = y_test-rg_pred

sns.displot(residuals,kind="kde")

plt.scatter(rg_pred,residuals)

from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error

print(mean_squared_error(y_test,rg_pred))
print(mean_absolute_error(y_test,rg_pred))

"""# R square and Adjusted R square
Formula
R^2 = 1 - SSR/SST
R^2 coefficient of determination
SSR = sum of square of residual
SST = totla sum of square
"""

from sklearn.metrics import r2_score
score = r2_score(y_test,rg_pred)
print(score)

"""Adjusted R2 = 1 - [(1-R2)*(n-1)/(n-k-1)]
where : 
R2: The R2 of the model n:The number of observation k:The number of predication
"""

1-(1-score)*(len(y_test)-1)/(len(y_test)-x_test.shape[1]-1)

"""# New Prediction"""

sd = scalar.transform(boston.data[0].reshape(1,-1))
model.predict(sd)

"""# Pickling the model file for deployment"""

import pickle

pickle.dump(rg,open("regmodel.pkl","wb"))

pickled_model = pickle.load(open("regmodel.pkl","rb"))

pickled_model.predict(sd)